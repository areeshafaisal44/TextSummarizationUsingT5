# ğŸ§  T5 Text Summarization â€” Fine-Tuning with Hugging Face Transformers

This project fine-tunes a **T5 (Text-To-Text Transfer Transformer)** model for **abstractive text summarization** using the **CNN/DailyMail news dataset** from Kaggle.  
The goal is to automatically generate concise and coherent summaries from long news articles.

---

## ğŸ“˜ Overview

Abstractive summarization involves **generating new sentences** that capture the main ideas of the text â€” similar to how a human writes a summary.  
We fine-tune **`t5-small`** or **`t5-base`** using **Hugging Face Transformers** and evaluate model performance using **ROUGE metrics**.

The complete pipeline includes:
- âœ… Data preprocessing (text + summary)
- âœ… Fine-tuning a pre-trained T5 model
- âœ… Evaluation using ROUGE scores
- âœ… Streamlit web app for interactive summarization
- âœ… GitHub integration for reproducibility

---

## ğŸ“‚ Dataset

**Dataset used:** [Newspaper Text Summarization (CNN/DailyMail)](https://www.kaggle.com/datasets/gowrishankarp/newspaper-text-summarization-cnn-dailymail)

Each data sample contains:
- **`article`** â†’ full-length news article  
- **`highlights`** â†’ target summary  

Download directly in Colab:
```python
!kaggle datasets download -d gowrishankarp/newspaper-text-summarization-cnn-dailymail
!unzip newspaper-text-summarization-cnn-dailymail.zip -d data/

âš™ï¸ Model & Tokenizer

We use the T5 architecture available from Hugging Face:

  Model: t5-small or t5-base

Tokenizer: T5Tokenizer

  Both model and tokenizer are loaded from:

  from transformers import T5ForConditionalGeneration, T5Tokenizer

ğŸš€ Fine-Tuning Pipeline
1ï¸âƒ£ Preprocessing
Clean text and summary pairs
Add prefix "summarize: " to each article (T5 format)
Tokenize using the T5Tokenizer

2ï¸âƒ£ Training
Fine-tune the model with the Seq2SeqTrainer API
Use ROUGE for evaluation
Save the best model in /content/t5_cnn_summary

3ï¸âƒ£ Evaluation
Generate summaries on the test set
Evaluate with ROUGE-1, ROUGE-2, and ROUGE-L metrics

ğŸ“ Directory Structure
T5-Text-Summarization/
â”‚
â”œâ”€â”€ data/                        # Dataset folder
â”œâ”€â”€ app.py                       # Streamlit app for summarization
â”œâ”€â”€ train_t5.ipynb               # Colab notebook for training
â”œâ”€â”€ t5_cnn_summary/              # Saved fine-tuned model
â”œâ”€â”€ requirements.txt             # Dependencies list
â””â”€â”€ README.md                    # Project documentation
